{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Analise do dataset de cachorros\n",
    "\n",
    "Nesse notebook vamos efetuar uma análise exploratória do dataset de cachorros a fim de entender as informações que lá existem e procurar algum padrão ou obter alguns insigths sobre o contexto.\n",
    "\n",
    "No final vamos procurar criar um modelo que possa prever a raça do cachorro de acordo com as features levantadas.\n",
    "\n",
    "Como premiça nosso modelo deve ter pelo menos 70% de acurácia e precisão."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Importação do dataset\n",
    "\n",
    "Inicialmente vamos importar o dataset, utilizando o pandas e vamos visulizar as informações através da biblioteca de gráficos Seaborn e Matplotlib."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"cachorros.json\")\n",
    "df.head()"
   ]
  },
  {
   "source": [
    "## Análise incial do dataset\n",
    "\n",
    "Vamos buscar visualizar como os dados estão categorizados, distribuídos e correlacionados."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Sex = df.Sex.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "source": [
    "### Histograma\n",
    "\n",
    "No histograma podemos visualizar a distribuição dos dados de acordo com a frequência que aparecem."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(12,8))\n",
    "\n",
    "plt.suptitle('Distribuições')\n",
    "\n",
    "sns.histplot(x='Age', data=df, kde=True, ax=ax[0][0]).set(title='Distribuição da idade', xlabel='Idade', ylabel='Quantidade')\n",
    "sns.histplot(x='Weight', data=df, kde=True, ax=ax[0][1]).set(title='Distribuição do peso', xlabel='Peso', ylabel='Quantidade')\n",
    "sns.histplot(x='Height', data=df, kde=True, ax=ax[1][0]).set(title='Distribuição do altura', xlabel='Altura', ylabel='Quantidade')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "### Boxplot\n",
    "\n",
    "O boxplot nos permitem visualizar como os dados estão distribuidos dentro dos quartiles e se existem outliers."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(12,8))\n",
    "\n",
    "plt.suptitle('Outliers')\n",
    "\n",
    "sns.boxplot(x='Age', data=df, ax=ax[0][0]).set(title='Outlier para Idade', xlabel='Idade')\n",
    "sns.boxplot(x='Weight', data=df, ax=ax[0][1]).set(title='Outlier para Peso', xlabel='Peso')\n",
    "sns.boxplot(x='Height', data=df, ax=ax[1][0]).set(title='Outlier para Altura', xlabel='Altura')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "### Correlação \n",
    "\n",
    "Podemos agora identificar informações que possam ser correlacionadas. Por correlacionadas podemos entender que dada uma variável X outra variavel Y pode aumentar ou diminuir na mesma medida que X aumenta ou diminui.\n",
    "\n",
    "Vale resaltar que correlação não implica em causualidade."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(ncols=3, figsize=(18, 10))\n",
    "\n",
    "plt.suptitle(\"Correlação entre variáveis\")\n",
    "\n",
    "corr = df.corr()\n",
    "sns.heatmap(corr, ax=ax1).set(title='Correlação')\n",
    "\n",
    "sns.scatterplot(x='Weight', y='Height', hue='Breed', data=df, ax=ax2).set(title='Gráfico de dispersão x Raça', xlabel='Peso', ylabel='Altura')\n",
    "sns.set(font_scale=1.4)\n",
    "\n",
    "sns.scatterplot(x='Weight', y='Height', hue='Sex', data=df, ax=ax3).set(title='Gráfico de dispersão x Sexo', xlabel='Peso', ylabel='Altura')\n",
    "sns.set(font_scale=1.4)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "#### Criação de coluna - Feature Engineering"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Category'] = pd.cut(df['Weight'], bins=[0, 15, 30, 100], labels=['small', 'medium', 'big'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.countplot(x='Category', data=df).set(title='Quantidade de cachorros por porte', xlabel='Categoria', ylabel='Quantidade')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "## Analise de variáveis categoricas\n",
    "\n",
    "Vamos agora analisar as variaveis categoricas, ou seja, variáveis que são expressas por textos, podendo elas serem ordinais ou nominais.\n",
    "\n",
    "### Cores"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,10))\n",
    "sns.countplot(data=df, y='Color', order=df.Color.value_counts().index).set(title='Quantidade de animais por cor', ylabel='Cor', xlabel='Quantidade', xticks=np.arange(0, 130, 10))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.Color.value_counts().keys())"
   ]
  },
  {
   "source": [
    "#### Transformação de colunas - Feature Engineering\n",
    "\n",
    "Vamos transformar nossa única coluna que contem as cores dos cachorros em várias colunas booleanas (Verdadeiro/Falso), com todas as cores, assinalando quais cores aquele animal possue. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.DataFrame(columns=['Cores'])\n",
    "d = d.append({'Cores': ['Azul']}, ignore_index=True)\n",
    "d = d.append({'Cores': ['Verde']}, ignore_index=True)\n",
    "d = d.append({'Cores': ['Verde', 'Azul']}, ignore_index=True)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "label = MultiLabelBinarizer()\n",
    "label.fit_transform(d['Cores'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(label.fit_transform(d['Cores'].values), columns=label.classes_)"
   ]
  },
  {
   "source": [
    "##### Tratamento dos valores\n",
    "\n",
    "Antes de iniciar o processo de criação de novas colunas, primeiro precisamos fazer um tratamento nos dados existentes, normalizando-os. \n",
    "\n",
    "* Remover caracteres especiais\n",
    "\n",
    "* Converter a palavra em um vetor\n",
    "\n",
    "* Traduzir as cores"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicionario = {\n",
    "    'abricot': 'damasco',\n",
    "    'tan': 'bronze',\n",
    "    'fawn': 'fulvo',\n",
    "    'rust': 'ferrugem',\n",
    "    'red': 'vermelho',\n",
    "    'blue': 'azul',\n",
    "    'gray': 'cinza',\n",
    "    'white': 'branco',\n",
    "    'casbronzeadoho': 'castanho',\n",
    "    'sable': 'areia'\n",
    "}\n",
    "\n",
    "def traduzir_palavras(text: str):\n",
    "    \n",
    "    for chave, valor in dicionario.items():\n",
    "       text = text.replace(chave, valor)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_colors(text: str):\n",
    "    text = ','.join(text.split(' e '))\n",
    "    text = ','.join(text.split(' & '))\n",
    "    text = ','.join(text.split(' - ')).lower()\n",
    "    text = traduzir_palavras(text)\n",
    "    return text.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Colors'] = df.Color.apply(split_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = MultiLabelBinarizer()\n",
    "colors = label.fit_transform(df['Colors'])\n",
    "df_colors = pd.DataFrame(colors, columns=label.classes_)\n",
    "df_colors.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_colors.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, df_colors], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "source": [
    "#### Personalidade"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,10))\n",
    "sns.countplot(y='Personality', data=df, order=df.Personality.value_counts().index).set(title='Personalidades', xlabel='Quantidade', ylabel='Personalidade', xticks=np.arange(0, 110, 10))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "## Treinamento de um modelo\n",
    "\n",
    "Vamos treinar um modelo para prever a raça de um cachorro. \n",
    "\n",
    "Primeiramente vamos dividir a base entre treino e teste com o objetivo de termos uma massa para treinamento e outra para vaildação a fim de validar se nosso modelo generaliza bem dados não vistos."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[df.columns.difference(['Category', 'Color', 'Colors', 'Origin', 'Personality', 'Breed'])]\n",
    "y = df['Breed']"
   ]
  },
  {
   "source": [
    "Vamos utilizar cerca de 75% da base para treinamento e 25% para validação"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.metrics import accuracy_score, precision_score, classification_report, confusion_matrix, SCORERS\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "source": [
    "#### Modelo Dummy\n",
    "\n",
    "Vamos criar um modelo Dummy a fim de validar qual será nossa base line."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = DummyClassifier()\n",
    "dummy.fit(X_train, y_train)\n",
    "\n",
    "y_dummy = dummy.predict(X_train)\n",
    "\n",
    "print(accuracy_score(y_train, y_dummy))\n",
    "print(precision_score(y_train, y_dummy, average='weighted'))\n",
    "print(classification_report(y_train, y_dummy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(confusion_matrix(y_train, y_dummy), columns=dummy.classes_, index=dummy.classes_)"
   ]
  },
  {
   "source": [
    "### Treinar um modelo mais inteligênte"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC(random_state=10)\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svc.predict(X_train)\n",
    "\n",
    "print(accuracy_score(y_train, y_pred))\n",
    "print(precision_score(y_train, y_pred, average='weighted'))\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(confusion_matrix(y_train, y_pred), columns=svc.classes_, index=svc.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = cross_validate(SVC(), X_train, y_train, cv=10, scoring=('accuracy', 'precision_macro'))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(result.get('test_accuracy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svc.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(precision_score(y_test, y_pred, average='weighted'))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(confusion_matrix(y_test, y_pred), columns=svc.classes_, index=svc.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}